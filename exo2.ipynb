{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Classification\n",
    "On peut transformer le problème initial en un problème de classification. Par une méthode de clustering, on peut répartir les charges de chauffage et de climatisation en 3 classes :\n",
    "**faibles**, **moyennes**, **élevées**. Les données se répartissent alors de la manière suivante :  \n",
    "\n",
    "| Classe | Code de la classe | Nombre d'exemples | Charges totales moyennes |\n",
    "| ------|------------------ | ---------------- | ------------------------|\n",
    "| élevée | 0 | 189 | 73.6 |\n",
    "| moyenne | 1 | 185 | 56.3 |\n",
    "| faible | 2 | 394 | 29.7 |\n",
    "\n",
    "Les étiquettes des classes se trouvent dans le fichier labels.txt.\n",
    "Nous allons comparer plusieurs méthodes d'apprentissage :  \n",
    "\n",
    "1. KNN  \n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors= XXX)\n",
    "#  Hyperparametre a regler : n_neighbors.\n",
    "```\n",
    "2. Arbres de décision\n",
    "```python\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "```\n",
    "3. SVM à noyau linéaire\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel = ’linear’)\n",
    "```\n",
    "4. SVM à noyau rbf\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma= XXX, kernel = ’rbf’)\n",
    "#  Hyperparametre a regler : gamma.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  ́Ecrivez le code permettant :  \n",
    "- de separer les données de travail en des donnees d’apprentissage et de test,\n",
    "- de selectionner les hyperparametres des algorithmes d’apprentissage sur l’ ́echantillon d’apprentissage par validation croisée,\n",
    "- d’afficher les scores de ces algorithmes  ́evalu es sur l’echantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_compactness</th>\n",
       "      <th>surface_area</th>\n",
       "      <th>wall_area</th>\n",
       "      <th>roof_area</th>\n",
       "      <th>overall_height</th>\n",
       "      <th>orientation</th>\n",
       "      <th>glazing_area</th>\n",
       "      <th>glazing_area_distribution</th>\n",
       "      <th>Yheat</th>\n",
       "      <th>Ycool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relative_compactness  surface_area  wall_area  roof_area  overall_height  \\\n",
       "0                  0.98         514.5      294.0     110.25             7.0   \n",
       "1                  0.98         514.5      294.0     110.25             7.0   \n",
       "2                  0.98         514.5      294.0     110.25             7.0   \n",
       "3                  0.98         514.5      294.0     110.25             7.0   \n",
       "4                  0.90         563.5      318.5     122.50             7.0   \n",
       "\n",
       "   orientation  glazing_area  glazing_area_distribution  Yheat  Ycool  \n",
       "0            2           0.0                          0  15.55  21.33  \n",
       "1            3           0.0                          0  15.55  21.33  \n",
       "2            4           0.0                          0  15.55  21.33  \n",
       "3            5           0.0                          0  15.55  21.33  \n",
       "4            2           0.0                          0  20.84  28.28  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "columns_of_dataset= ['relative_compactness', 'surface_area', 'wall_area', 'roof_area', 'overall_height', 'orientation', 'glazing_area', 'glazing_area_distribution', 'Yheat', 'Ycool']\n",
    "\n",
    "# The correct delimiter here is spaces so \\s+ works correctly\n",
    "data = pd.read_csv(\"ENB2012_data.dat\", header=None, delimiter='\\s+' , names=columns_of_dataset)\n",
    "\n",
    "# read labels\n",
    "target = np.loadtxt('labels.txt', dtype='int')\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the length of our targets\n",
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = data.iloc[:, 0:8] # or data[:, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données en un échantillon d'apprentissage et un échantillon test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score K-NN : 0.927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# K-NN\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9, 11]}\n",
    "knn = KNeighborsClassifier()\n",
    "clf_knn = GridSearchCV(knn, param_grid, cv=5)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "score_knn = clf_knn.score(X_test, y_test)\n",
    "print(\"Score K-NN : {:.3f}\".format(score_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score arbre de décision : 0.990\n"
     ]
    }
   ],
   "source": [
    "# Arbre de décision\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "# no parameter for this model\n",
    "clf_dtc = GridSearchCV(dtc, {}, cv=5)\n",
    "clf_dtc.fit(X_train, y_train)\n",
    "score_dtc = clf_dtc.score(X_test, y_test)\n",
    "print(\"Score arbre de décision : {:.3f}\".format(score_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score SVM linéaire : 0.901\n"
     ]
    }
   ],
   "source": [
    "# SVM linéaire\n",
    "svm_lin = SVC(kernel='linear', random_state=42)\n",
    "# no parameter for this model\n",
    "clf_svm_lin = GridSearchCV(svm_lin, {}, cv=5)\n",
    "clf_svm_lin.fit(X_train, y_train)\n",
    "score_svm_lin = clf_svm_lin.score(X_test, y_test)\n",
    "print(\"Score SVM linéaire : {:.3f}\".format(score_svm_lin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score SVM rbf : 0.896\n"
     ]
    }
   ],
   "source": [
    "# SVM rbf\n",
    "param_grid = {'gamma': [0.1, 0.5, 1, 5, 10]}\n",
    "svm_rbf = SVC(kernel='rbf', random_state=42)\n",
    "clf_svm_rbf = GridSearchCV(svm_rbf, param_grid, cv=5)\n",
    "clf_svm_rbf.fit(X_train, y_train)\n",
    "score_svm_rbf = clf_svm_rbf.score(X_test, y_test)\n",
    "print(\"Score SVM rbf : {:.3f}\".format(score_svm_rbf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "Pour chacune des méthodes, calculez l’intervalle à 95% de confiance auquel le score doit appartenir.   \n",
    "Rappel : si e est l'erreur estimée, le rayon de l’intervalle d’erreur à la confiance de 95% est  ́egal à : 1.96√e(1 −e)/N , où N est le nombre d'exemples sur lequel l'évaluation a  été faite.  \n",
    "\n",
    "Pour calculer l'intervalle à 95% de confiance pour chaque méthode,on doit d'abord estimer l'erreur (e) et le nombre d'exemples sur lequel l'évluation a été faite (N)  \n",
    "Pour chaque méthode , nous allons estimer l'erreur (e) comme étant 1-accuracy_score. Accuracy score étant  ici le métrique de performance d'évaluation d'un modèle de classification a bien prédire les données. Nous l'avons en appelant la méthode score().  \n",
    "le nombre d'exemple sur lequel l'évaluation a été faite est juste le nombre d'exemple du test set. On l'obtient en accedant au shape de l'attribut du test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 95% confidence interval: 0.9375 ± 0.0342\n",
      "Decision tree 95% confidence interval: 0.9896 ± 0.0144\n",
      "Linear SVM 95% confidence interval: 0.9010 ± 0.0422\n",
      "RBF SVM 95% confidence interval: 0.9010 ± 0.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EKANE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the classifiers with the hyperparameters\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "lin_svm_clf = SVC(kernel='linear')\n",
    "rbf_svm_clf = SVC(kernel='rbf', gamma=0.1)\n",
    "\n",
    "# Fit the classifiers on the training data\n",
    "knn_clf.fit(X_train, y_train)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "lin_svm_clf.fit(X_train, y_train)\n",
    "rbf_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the accuracy scores on the test set\n",
    "knn_score = knn_clf.score(X_test, y_test)\n",
    "tree_score = tree_clf.score(X_test, y_test)\n",
    "lin_svm_score = lin_svm_clf.score(X_test, y_test)\n",
    "rbf_svm_score = rbf_svm_clf.score(X_test, y_test)\n",
    "\n",
    "# Calculate the error estimate (e) and the number of examples (N) for each method\n",
    "knn_e = 1 - knn_score\n",
    "knn_N = X_test.shape[0]\n",
    "\n",
    "tree_e = 1 - tree_score\n",
    "tree_N = X_test.shape[0]\n",
    "\n",
    "lin_svm_e = 1 - lin_svm_score\n",
    "lin_svm_N = X_test.shape[0]\n",
    "\n",
    "rbf_svm_e = 1 - rbf_svm_score\n",
    "rbf_svm_N = X_test.shape[0]\n",
    "\n",
    "# Calculate the 95% confidence interval for each method\n",
    "knn_interval = 1.96 * math.sqrt((knn_e * (1 - knn_e)) / knn_N)\n",
    "tree_interval = 1.96 * math.sqrt((tree_e * (1 - tree_e)) / tree_N)\n",
    "lin_svm_interval = 1.96 * math.sqrt((lin_svm_e * (1 - lin_svm_e)) / lin_svm_N)\n",
    "rbf_svm_interval = 1.96 * math.sqrt((rbf_svm_e * (1 - rbf_svm_e)) / rbf_svm_N)\n",
    "\n",
    "# Print the results\n",
    "print(\"KNN 95% confidence interval: {:.4f} ± {:.4f}\".format(knn_score, knn_interval))\n",
    "print(\"Decision tree 95% confidence interval: {:.4f} ± {:.4f}\".format(tree_score, tree_interval))\n",
    "print(\"Linear SVM 95% confidence interval: {:.4f} ± {:.4f}\".format(lin_svm_score, lin_svm_interval))\n",
    "print(\"RBF SVM 95% confidence interval: {:.4f} ± {:.4f}\".format(rbf_svm_score, rbf_svm_interval))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\n",
    "En examinant les résultats, on peut voir que l'algorithme de l'arbre de décision a la performance la plus élevée avec un score moyen de 0,9896 et un intervalle de confiance étroit de ± 0,0144. En revanche, les algorithmes SVM ont tous deux des performances plus faibles avec des scores moyens de 0,9010 et des intervalles de confiance plus larges de ± 0,0422. L'algorithme KNN a également une performance élevée avec un score moyen de 0,9375 et un intervalle de confiance de ± 0,0342.\n",
    "\n",
    "En général, l'algorithme de l'arbre de décision semble être le meilleur choix pour ce problème de classification, en raison de sa performance supérieure et de l'étroitesse de son intervalle de confiance ce qui vient confirmer sa performance en utilisant le cross validation.   \n",
    "\n",
    "Cependant, il est important de noter que les performances peuvent varier en fonction des données et que l'utilisation d'un autre ensemble de données pourrait donner des résultats différents."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test de McNemar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
